{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead2e41c",
   "metadata": {},
   "source": [
    "# Step 1: Install the required Python package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a21a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cbfaec",
   "metadata": {},
   "source": [
    "# Step 2: Import and set up Ollama client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb8bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18371bc9",
   "metadata": {},
   "source": [
    "# Step 3: Define a sample Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69838b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_jd = \"\"\"\n",
    "Scientist - Machine Learning\n",
    "At ABB, we are dedicated to addressing global challenges. Our core values: care, courage, curiosity, and collaboration - combined with a focus on diversity, inclusion, and equal opportunities - are key drivers in our aim to empower everyone to create sustainable solutions.\n",
    "Write the next chapter of your ABB story.\n",
    "\n",
    "This position reports to\n",
    "\n",
    "Research Department Manager\n",
    "Your role and responsibilities\n",
    "\n",
    "In this role, you will have the opportunity to explore emerging technologies, creates intellectual property, and strengthens existing and future ABB offerings. We also provide R&D consultancy services to ABB Divisions and reap the benefits of open innovation by collaborating with Universities and startup companies. You will work in dynamic and creative teams, with a wide range of experience and expertise, carrying out applied research projects developing software engineering techniques to build intelligent systems for process industries.\n",
    "\n",
    "The work model for the role is Hybrid. #LI-Hybrid\n",
    "\n",
    "This role contributes to the India Corporate Research Center (INCRC), located in Bangalore.\n",
    "\n",
    "You will be mainly accountable for:\n",
    "• Use cases and requirements gathering in cooperation with ABB’s business divisions and end customers for data-driven solutions.\n",
    "• Evaluating and developing of mathematical algorithms and machine learning libraries for applications related to Industrial Process Automation business.\n",
    "• Identifying and evaluating multiple design approaches and corresponding architectural solutions with a design rationale for machine learning systems.\n",
    "• Developing proof of concepts, prototypes, and supporting pilot evaluation and productization of solutions.\n",
    "• Adapting and optimizing machine learning algorithms to better utilize GPU and distributed clusters.\n",
    "• Communicating project results to experts and non-expert audiences.\n",
    "• Creating Intellectual Property - Invention disclosures and publishing in scientific conferences and journals.\n",
    "• Living ABB’s core values of safety and integrity, which means taking responsibility for your own actions while caring for your colleagues and the business.\n",
    "Qualifications for the role\n",
    "• Ph.D. in a topic related to AI/ML in engineering from a reputed University with a good publication record and with a minimum of two years of relevant industrial research or post-doctoral experience.\n",
    "• Proficiency in one or more programming languages and corresponding ML frameworks and libraries for interacting with industrial data.\n",
    "• Good knowledge of supervised, unsupervised, semi-supervised, reinforcement learning techniques, time-series analysis, signal processing and related areas.\n",
    "• Exposure to design, implementation and deployment of industrial machine learning systems with MLOps and efficient use of GPUs is preferred.\n",
    "• Should have ability to collaborate and communicate effectively in English with internal and external partners including academic community.\n",
    "\n",
    "More about us\n",
    "\n",
    "\"Our Process Automation business offers a range of solutions for process and hybrid industries, including our industry-specific integrated automation, electrification and digital solutions, control technologies, software and advanced services, as well as measurement & analytics, marine and turbocharging offerings.\n",
    "\n",
    "We value people from different backgrounds. Apply today for your next career step within ABB and visit www.abb.com to learn about the impact of our solutions across the globe. #MyABBStory\n",
    "\n",
    "\"It has come to our attention that the name of ABB is being used for asking candidates to make payments for job opportunities (interviews, offers). Please be advised that ABB makes no such requests. All our open positions are made\n",
    "available on our career portal for all fitting the criteria to apply. ABB does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection to recruitment with ABB, even if is\n",
    "claimed that the money is refundable. ABB is not liable for such transactions.\n",
    "\n",
    "For current open positions you can visit our career website https://global.abb/group/en/careers and apply. Please refer to detailed recruitment fraud caution notice using the link https://global.abb/group/en/careers/how-to-apply/fraud-warning\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e743078",
   "metadata": {},
   "source": [
    "# Step 4: Build prompt for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8d77c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an expert job description parser.\n",
    "\n",
    "From the following job description, extract only the following details in the exact format below:\n",
    "\n",
    "(Name: [Name or Not Available]  \n",
    "Years of Experience: [Years or Not Available]  \n",
    "Key Skills: [Skills or Not Available]  \n",
    "Technologies / Tools: [Tools or Not Available]  \n",
    "Estimated Experience Level: [Junior/Mid/Senior or Not Available])\n",
    "\n",
    "Only return the above 5 lines. Be concise and avoid explanation or additional formatting.\n",
    "\n",
    "Here is the job description:\n",
    "{demo_jd}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e82e791",
   "metadata": {},
   "source": [
    "# Step 5: Send the prompt to Phi-2 via Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d42152b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat(model=\"phi\", messages=[{\"role\": \"user\", \"content\": prompt}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ab3b5",
   "metadata": {},
   "source": [
    "# Step 6: Display the structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b12c24aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Structured JD Output ---\n",
      "\n",
      " \n",
      "\n",
      "# Here is the Python code that can extract the required information from the job description.\n",
      "\n",
      "import re\n",
      "\n",
      "# Define the job description as a string\n",
      "job_description = \"Scientist - Machine Learning\\nAt ABB, we are dedicated to addressing global challenges. Our core values: care, courage, curiosity, and collaboration ------------> combined with a focus on diversity, inclusion, and equal opportunities -------------> are key drivers in our aim to empower everyone to create sustainable solutions. Write the next chapter of your ABB story.\"\n",
      "\n",
      "# Define the pattern for job description as a regular expression\n",
      "pattern = r\"Name: \\w+ | Years of Experience: \\d+\\s?years | Key Skills: \\w+| Technologies/Tools: \\w+| Estimated Experience Level: (Junior|Mid|Senior)\\s?\"\n",
      "\n",
      "# Use re.findall to match all the patterns in the job description and store them in a list\n",
      "job_data = re.findall(pattern, job_description)\n",
      "\n",
      "# Print out the extracted details\n",
      "print(\"Name: \", job_data[1]) if len(job_data) > 0 else \"Not Available\" # Extract name or Not Available\n",
      "print(\"Years of Experience: \", job_data[2]) if len(job_data) > 1 else \"Not Available\" # Extract years or Not Available\n",
      "print(\"Key Skills: \", job_data[3]) # Extract skills or Not Available\n",
      "print(\"Technologies/Tools: \", job_data[4]) # Extract tools or Not Available\n",
      "print(\"Estimated Experience Level: \", job_data[5]) # Extract experience level or Not Available\n",
      "\n",
      "Output:\n",
      "Name: \n",
      "Years of Experience: \n",
      "Key Skills: \n",
      "Technologies/Tools: \n",
      "Estimated Experience Level: \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Structured JD Output ---\\n\")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df306f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ollama' has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Test if you can communicate with the local Ollama model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mollama\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m(\n\u001b[32m      5\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mllama2\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# Replace with the correct model name if different\u001b[39;00m\n\u001b[32m      6\u001b[39m     messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHello, how are you?\u001b[39m\u001b[33m\"\u001b[39m}]\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'ollama' has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Test if you can communicate with the local Ollama model\n",
    "response = ollama.chat(\n",
    "    model=\"llama2\",  # Replace with the correct model name if different\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d5133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e2c371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850d300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
